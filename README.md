# Text2Video-GenAI

This project demonstrates how to generate short AI-generated videos from natural language prompts using diffusion-based generative models. It uses Google Colab for execution and leverages state-of-the-art techniques for text-to-video generation.

## ğŸ“Œ Features
- Input a simple text prompt and generate a video.
- Uses powerful pre-trained diffusion models.
- Outputs short MP4 videos directly in Colab.
- Easy-to-use and beginner-friendly interface.

## ğŸš€ Getting Started
1. Open the [Colab Notebook](https://colab.research.google.com/drive/1rRtcZdv4a2hF4nwY7AQspXsPF-u0i8v-?usp=sharing).
2. Run all cells step-by-step.
3. Enter your desired text prompt when prompted.
4. Wait for video generation to complete.

## ğŸ§  Model & Backend
- Diffusion models for text-to-video synthesis.
- Optimized for Colab environments.
- No local GPU required.

## ğŸ“½ï¸ Output Example
> **Prompt**: "A cat surfing on the ocean at sunset"  
> **Output**: 5-second AI-generated animation (MP4 format)

## ğŸ› ï¸ Requirements
- Google Colab
- No local installations needed

## ğŸ“š References
- Google Research
- HuggingFace Diffusers
- Prompt Engineering techniques

---

Feel free to fork, explore, and enhance this project!

