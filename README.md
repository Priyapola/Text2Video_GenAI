# Text2Video-GenAI

This project demonstrates how to generate short AI-generated videos from natural language prompts using diffusion-based generative models. It uses Google Colab for execution and leverages state-of-the-art techniques for text-to-video generation.

## 📌 Features
- Input a simple text prompt and generate a video.
- Uses powerful pre-trained diffusion models.
- Outputs short MP4 videos directly in Colab.
- Easy-to-use and beginner-friendly interface.

## 🚀 Getting Started
1. Open the [Colab Notebook](https://colab.research.google.com/drive/1rRtcZdv4a2hF4nwY7AQspXsPF-u0i8v-?usp=sharing).
2. Run all cells step-by-step.
3. Enter your desired text prompt when prompted.
4. Wait for video generation to complete.

## 🧠 Model & Backend
- Diffusion models for text-to-video synthesis.
- Optimized for Colab environments.
- No local GPU required.

## 📽️ Output Example
> **Prompt**: "A cat surfing on the ocean at sunset"  
> **Output**: 5-second AI-generated animation (MP4 format)

## 🛠️ Requirements
- Google Colab
- No local installations needed

## 📚 References
- Google Research
- HuggingFace Diffusers
- Prompt Engineering techniques

---

Feel free to fork, explore, and enhance this project!

